{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s2465922/miniconda3/envs/dl/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data=pd.read_csv('/vol/home/s2465922/data/crime_from_2001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the crime incidents of recent 6 year\n",
    "df=data[data.Year>2014]\n",
    "\n",
    "# extract needed columns\n",
    "df=df[['Date','IUCR','Location Description','Community Area']]\n",
    "\n",
    "# remove rows that has nan values\n",
    "df=df.dropna(how='any')\n",
    "\n",
    "# convert time string to datetime type\n",
    "df['Date']=pd.to_datetime(df['Date'],format='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# convert community area as str type\n",
    "df['Community Area']=df['Community Area'].astype(int).astype(str)\n",
    "\n",
    "# extract hour\n",
    "df['hour']=df['Date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read criminal IUCR codes\n",
    "iucr=pd.read_csv('/vol/home/s2465922/data/crime_iucr.csv')\n",
    "iucr['IUCR']=iucr['IUCR'].apply(lambda s: '0'+s if len(s)<4 else s)\n",
    "iucr.loc[iucr['PRIMARY DESCRIPTION']=='OTHER OFFENSE ','PRIMARY DESCRIPTION']='OTHER OFFENSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add primary and secondary description based on matched IUCR code\n",
    "df=df.set_index('IUCR')\n",
    "iucr=iucr.set_index('IUCR')\n",
    "df['primary_type']=iucr['PRIMARY DESCRIPTION']\n",
    "df['secondary_description']=iucr['SECONDARY DESCRIPTION']\n",
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Col2'].isnull()]\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# generate texts and clean data \n",
    "\n",
    "class Processor:\n",
    "  def __init__(self):\n",
    "    self.puncs='[+/,.;:?!()]+'\n",
    "    self.min_word_df=50\n",
    "    self.min_num_words=3\n",
    "  \n",
    "  def make_text(self, df):\n",
    "    df['text']=df[['primary_type','secondary_description','Location Description']].values.tolist()\n",
    "    return df\n",
    "  \n",
    "  def get_word2inc(self,df):\n",
    "    '''\n",
    "    return {word: document frequency}\n",
    "    '''\n",
    "    word2inc={}\n",
    "    inc2text=df['text'].to_dict()\n",
    "    for i in inc2text:\n",
    "      for w in inc2text[i]:\n",
    "        if w in word2inc:\n",
    "          word2inc[w].add(i)\n",
    "        else:\n",
    "          word2inc[w]={i}\n",
    "    return word2inc\n",
    "  \n",
    "  \n",
    "  def clean_word(self,df):\n",
    "    '''\n",
    "    delete words that occur less than min_word_df\n",
    "    '''\n",
    "    word2inc=self.get_word2inc(df)\n",
    "    \n",
    "    # modify dataframe\n",
    "    for w in word2inc:\n",
    "      if len(word2inc[w])<=self.min_word_df:\n",
    "        for i in word2inc[w]:\n",
    "          df['text'][i].remove(w)\n",
    "    return df\n",
    "  \n",
    "  def clean_data(self,df):\n",
    "    '''\n",
    "    delete examples where number of keywords less than min_num_words\n",
    "    '''\n",
    "    tmp=pd.DataFrame(df['text'].apply(len))\n",
    "    tmp.columns=['numWords']\n",
    "    deleted=tmp[tmp['numWords']<self.min_num_words].index.tolist()\n",
    "    df=df.drop(deleted)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf=df.copy()\n",
    "ps=Processor()\n",
    "cdf=ps.make_text(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf=ps.clean_word(cdf)\n",
    "cdf=ps.clean_data(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rc=cdf.groupby(by=['primary_type','Community Area']).size().reset_index()\n",
    "# rc.columns=['primary_type','community_area','count']\n",
    "# rc['primary_type']=rc['primary_type'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_type</th>\n",
       "      <th>community_area</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arson</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>assault</td>\n",
       "      <td>34</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>battery</td>\n",
       "      <td>34</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>burglary</td>\n",
       "      <td>34</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>concealed carry license violation</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>crim sexual assault</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>criminal damage</td>\n",
       "      <td>34</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>criminal trespass</td>\n",
       "      <td>34</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>deceptive practice</td>\n",
       "      <td>34</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>gambling</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>homicide</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>interference with public officer</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>intimidation</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>kidnapping</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>liquor law violation</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>motor vehicle theft</td>\n",
       "      <td>34</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>narcotics</td>\n",
       "      <td>34</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>offense involving children</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>other offense</td>\n",
       "      <td>34</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>public peace violation</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>robbery</td>\n",
       "      <td>34</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>sex offense</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>stalking</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>theft</td>\n",
       "      <td>34</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>weapons violation</td>\n",
       "      <td>34</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           primary_type community_area  count\n",
       "27                                arson             34      2\n",
       "104                             assault             34    378\n",
       "181                             battery             34    992\n",
       "258                            burglary             34    230\n",
       "330   concealed carry license violation             34      1\n",
       "400                 crim sexual assault             34     21\n",
       "477                     criminal damage             34    536\n",
       "554                   criminal trespass             34    186\n",
       "631                  deceptive practice             34    470\n",
       "696                            gambling             34      1\n",
       "751                            homicide             34      6\n",
       "827    interference with public officer             34     11\n",
       "903                        intimidation             34      5\n",
       "979                          kidnapping             34      1\n",
       "1054               liquor law violation             34     16\n",
       "1126                motor vehicle theft             34    236\n",
       "1203                          narcotics             34    107\n",
       "1352         offense involving children             34     21\n",
       "1429                      other offense             34    186\n",
       "1602             public peace violation             34     17\n",
       "1679                            robbery             34    458\n",
       "1756                        sex offense             34     22\n",
       "1833                           stalking             34      3\n",
       "1910                              theft             34   1461\n",
       "1987                  weapons violation             34     73"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rc[rc['community_area']=='34']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(cdf, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeTable:\n",
    "  def __init__(self,df):\n",
    "    self.df=df\n",
    "  \n",
    "  def make_nodetable(self):\n",
    "    '''\n",
    "    retuen node2idx, idx2node\n",
    "    '''\n",
    "    nodes=[]\n",
    "    nodes.extend(self.regions)\n",
    "    nodes.extend(self.hours)\n",
    "    nodes.extend(self.words)\n",
    "    self.node2idx=dict((x,i) for i, x in enumerate(nodes))\n",
    "    self.idx2node=dict((i,x) for i, x in enumerate(nodes))\n",
    "    \n",
    "  def make_node2inc(self):\n",
    "    '''\n",
    "    return unit2inc\n",
    "    '''\n",
    "    self.node2inc={}\n",
    "    inc2units=[]\n",
    "    units=['Community Area', 'hour', 'primary_type', 'secondary_description', 'Location Description']\n",
    "    for u in units:\n",
    "      inc2units.append(self.df[u].to_dict())\n",
    "\n",
    "    for i2u in inc2units:\n",
    "      for k, v in i2u.items():\n",
    "        vid=self.node2idx[v]\n",
    "        if vid in self.node2inc:\n",
    "          self.node2inc[vid].add(k)\n",
    "        else:\n",
    "          self.node2inc[vid]={k}\n",
    "    \n",
    "  def make_codetable(self):\n",
    "\n",
    "    self.regions=pd.unique(self.df['Community Area']).tolist()\n",
    "    self.hours=pd.unique(self.df['hour']).tolist()\n",
    "    self.words=set(pd.unique(self.df['primary_type']))\\\n",
    "              .union(set(pd.unique(self.df['secondary_description'])))\\\n",
    "              .union(set(pd.unique(self.df['Location Description'])))\n",
    "    self.words=list(self.words)\n",
    "    self.make_nodetable()\n",
    "    self.make_node2inc()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=CodeTable(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.make_codetable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cooccur:\n",
    "  def __init__(self,ct):\n",
    "    self.ct=ct\n",
    "  \n",
    "  def lookup(self, co_type):\n",
    "    '''\n",
    "    return the two units based on co_type \n",
    "    '''\n",
    "    if co_type=='rw':\n",
    "      u1=self.ct.regions\n",
    "      u2=self.ct.words\n",
    "      \n",
    "    if co_type=='rh':\n",
    "      u1=self.ct.regions\n",
    "      u2=self.ct.hours\n",
    "      \n",
    "    if co_type=='hw':\n",
    "      u1=self.ct.hours\n",
    "      u2=self.ct.words\n",
    "      \n",
    "    if co_type=='ww':\n",
    "      u1=self.ct.words\n",
    "      u2=self.ct.words\n",
    "    \n",
    "    return u1,u2\n",
    "    \n",
    "  def create_cooccur_matrix(self, co_type):\n",
    "\n",
    "    u1, u2=self.lookup(co_type)\n",
    "    \n",
    "    co=np.zeros((len(u1), len(u2)), dtype=int)\n",
    "    for i in range(len(u1)):\n",
    "      for j in range(len(u2)):\n",
    "        u1_id=self.ct.node2idx[u1[i]]\n",
    "        u2_id=self.ct.node2idx[u2[j]]\n",
    "        co[i,j]=len(self.ct.node2inc[u1_id] & self.ct.node2inc[u2_id])\n",
    "    return co\n",
    "  \n",
    "  def create_cooccur_edges(self, co_matrix, edge_type):\n",
    "    edges=[]\n",
    "    \n",
    "    u1, u2 =self.lookup(edge_type)\n",
    "    \n",
    "#     norm_co=co_matrix/len(cdf)\n",
    "        \n",
    "    for i in range(co_matrix.shape[0]): \n",
    "      \n",
    "      if edge_type==\"ww\":\n",
    "        j_range=np.arange(i+1,co_matrix.shape[1])\n",
    "      else:\n",
    "        j_range=np.arange(co_matrix.shape[1])\n",
    "        \n",
    "      for j in j_range:\n",
    "        c=co_matrix[i,j]\n",
    "        if c>0:\n",
    "          u1_id=self.ct.node2idx[u1[i]]\n",
    "          u2_id=self.ct.node2idx[u2[j]]\n",
    "          edges.append((u1_id, u2_id, c))\n",
    "          edges.append((u2_id, u1_id, c))\n",
    "        \n",
    "    return edges\n",
    "  \n",
    "  def save_edges(self, edge_type, edge_lst):\n",
    "    file=edge_type+'_edges.txt'\n",
    "    with open(file, 'w') as f:\n",
    "      for edge in  edge_lst:\n",
    "          f.write(\"\\t\".join(str(e) for e in edge))\n",
    "          f.write(\"\\n\")\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "co=Cooccur(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_types=['rw','rh','hw','ww']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_matrix=[]\n",
    "for i in range(len(graph_types)):\n",
    "  co_matrix.append(co.create_cooccur_matrix(graph_types[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_edges=[]\n",
    "for i in range(len(graph_types)):\n",
    "  gt=graph_types[i]\n",
    "  co_edges.append(co.create_cooccur_edges(co_matrix[i], gt))\n",
    "  co.save_edges(gt,co_edges[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tfidf:\n",
    "  def __init__(self, co_matrix):\n",
    "    self.rw_matrix=co_matrix[0]\n",
    "    self.rh_matrix=co_matrix[1]\n",
    "    self.hw_matrix=co_matrix[2]\n",
    "    self.ww_matrix=co_matrix[3]\n",
    "\n",
    "  def get_tfidf(self,co):\n",
    "    '''\n",
    "    input: an cooccurrence matrix\n",
    "    return: an matrix with tf-idf weighting by treating each row as a document and \n",
    "    each column as a word\n",
    "    '''\n",
    "    tf=np.log10(co+1)\n",
    "    df=np.sum(co!=0,axis=0)\n",
    "    idf=np.log10(len(co)/df)\n",
    "\n",
    "    return tf*idf\n",
    "  \n",
    "#   def get_pair_tfidf(self, co):\n",
    "#     tfidf=self.get_tfidf(co)\n",
    "    \n",
    "#     tfidf_=self.get_tfidf(co.T)\n",
    "    \n",
    "#     return tfidf, tfidf_\n",
    "  \n",
    "  def vectorize(self):\n",
    "    rvec=self.get_tfidf(self.rw_matrix)\n",
    "    hvec=self.get_tfidf(self.hw_matrix)\n",
    "    wvec=self.get_tfidf(self.ww_matrix)\n",
    "    \n",
    "    self.embeddings=np.r_[rvec,hvec,wvec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "td=tfidf(co_matrix)\n",
    "td.vectorize() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "\n",
    "class SVD:\n",
    "  def __init__(self, co_matrix, K=24):\n",
    "    self.rw_matrix=co_matrix[0]\n",
    "    self.rh_matrix=co_matrix[1]\n",
    "    self.hw_matrix=co_matrix[2]\n",
    "    self.ww_matrix=co_matrix[3]\n",
    "    self.K=K\n",
    "\n",
    "  def decompose(self, co):\n",
    "    u,s,v=svd(co)\n",
    "    u1_vec=u[:,:self.K]\n",
    "    u2_vec=v.T[:,:self.K]\n",
    "    return u1_vec, u2_vec\n",
    "  \n",
    "  def get_embeddings(self):\n",
    "    rw, wr=self.decompose(self.rw_matrix)\n",
    "    rh, hr=self.decompose(self.rh_matrix)\n",
    "    hw, wh=self.decompose(self.hw_matrix)\n",
    "    ww, ww_=self.decompose(self.ww_matrix)\n",
    "    \n",
    "#     rvec=np.maximum(rw,rh)\n",
    "#     hvec=np.maximum(hw,hr)\n",
    "#     wvec=np.maximum(wr,wh)\n",
    "\n",
    "    rvec=(rw+rh)/2\n",
    "    hvec=(hr+hw)/2\n",
    "    wvec=(wr+wh+ww)/3\n",
    "  \n",
    "    \n",
    "    self.embeddings=np.r_[rvec,hvec,wvec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=SVD(co_matrix)\n",
    "sd.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from utils import *\n",
    "from alias import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGraph:\n",
    "  def __init__(self, graph_type,args):\n",
    "    self.graph=nx.read_edgelist(graph_type+\"_edges.txt\", create_using=nx.DiGraph(), \n",
    "                  nodetype=int, data=[('weight', np.float)])\n",
    "    self.args=args\n",
    "    self.n2i=dict((n,i) for i, n in enumerate(self.graph.nodes()))\n",
    "    self.i2n=dict((i,n) for i, n in enumerate(self.graph.nodes()))\n",
    "    \n",
    "    self.get_sampling_table()\n",
    "    \n",
    "  def get_sampling_table(self):\n",
    "    \n",
    "    # create sampling table for vertex\n",
    "    \n",
    "    numNodes=self.graph.number_of_nodes()\n",
    "    node_degree=np.zeros(numNodes)\n",
    "    \n",
    "    for edge in self.graph.edges():\n",
    "      node_degree[self.n2i[edge[0]]]+=self.graph[edge[0]][edge[1]].get('weight')\n",
    "      \n",
    "    total_sum=sum([pow(node_degree[i], self.args.power) for i in range(numNodes)])\n",
    "    \n",
    "    norm_prob=[pow(node_degree[j], self.args.power)/total_sum for j in range(numNodes)]\n",
    "    \n",
    "    self.node_accept, self.node_alias=create_alias_table(norm_prob)\n",
    "    \n",
    "    # create sampling table for edge\n",
    "    numEdges=self.graph.number_of_edges()\n",
    "    total_sum=sum(pow(self.graph[edge[0]][edge[1]].get('weight'),self.args.power)\n",
    "                  for edge in self.graph.edges())\n",
    "    norm_prob=[pow(self.graph[edge[0]][edge[1]].get('weight'),self.args.power)\n",
    "               /total_sum for edge in self.graph.edges()]\n",
    "\n",
    "    \n",
    "    self.edge_accept, self.edge_alias=create_alias_table(norm_prob)\n",
    "  \n",
    "  def batch_iter(self):\n",
    "    '''\n",
    "    batch_size*example. each example: [sourceID, destinationID] [sign]\n",
    "    '''\n",
    "    \n",
    "    data_size=self.graph.number_of_edges()\n",
    "    shuffle_indice=np.random.permutation(np.arange(data_size))\n",
    "    edges = [(edge[0], edge[1]) for edge in self.graph.edges()]\n",
    "    \n",
    "    # positive or negative mod\n",
    "    s=[]\n",
    "    d=[]\n",
    "    sign=[]\n",
    "    \n",
    "    for i in range(self.args.num_group):\n",
    "      \n",
    "      # generate positive edges\n",
    "      if np.random.random()>=self.edge_accept[shuffle_indice[i]]:\n",
    "        shuffle_indice[i]=self.edge_alias[shuffle_indice[i]]\n",
    "        \n",
    "      cur_s=edges[shuffle_indice[i]][0]\n",
    "      cur_d=edges[shuffle_indice[i]][1]\n",
    "      \n",
    "      s.append(cur_s)\n",
    "      d.append(cur_d)\n",
    "      sign.append(1)\n",
    "    \n",
    "    # generate negative edges, neg_ratio \n",
    "      s.extend([cur_s]*self.args.neg_ratio)\n",
    "      sign.extend([-1]*self.args.neg_ratio)\n",
    "      for i in range(self.args.neg_ratio):\n",
    "        while True :\n",
    "          d_neg=self.i2n[alias_sample(self.node_accept, self.node_alias)]\n",
    "          if d_neg not in self.graph[s[-1]]:\n",
    "            d.append(d_neg)\n",
    "            break\n",
    "            \n",
    "    return np.array(s),np.array(d),np.array(sign)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeGraph:\n",
    "  def __init__(self, args, nNodes):\n",
    "    self.args=args\n",
    "    self.nNodes=nNodes\n",
    "    self.gt=['rw','rh','hw','ww','rr','hh']\n",
    "    self.graphs=[]\n",
    "    for i in range(len(self.gt)):\n",
    "      self.graphs.append(BiGraph(self.gt[i],args))\n",
    "    \n",
    "    self.model=self.create_model()\n",
    "  \n",
    "  def line_loss(self,y_true, y_pred):\n",
    "    '''\n",
    "    y_true=1 if positive example else -1\n",
    "    '''\n",
    "    return -K.mean(K.log(K.sigmoid(y_true*y_pred)))\n",
    "\n",
    "  def create_model(self):\n",
    "    '''\n",
    "    input: two nodes (id)\n",
    "    output: inner product of embedding vectors for two nodes\n",
    "    '''\n",
    "    vi=Input(shape=(1,))\n",
    "    vj=Input(shape=(1,))\n",
    "\n",
    "    vi_emb=Embedding(self.nNodes, self.args.embedding_size)(vi)\n",
    "    vj_emb=Embedding(self.nNodes, self.args.embedding_size)(vj)\n",
    "\n",
    "    sim=Lambda(lambda x: tf.reduce_sum(x[0]*x[1], axis=-1))([vi_emb, vj_emb])\n",
    "\n",
    "    model=Model(inputs=[vi,vj], outputs=[sim])\n",
    "\n",
    "    return model\n",
    " \n",
    "#   def get_graph_sampling_table(self):\n",
    "#     num_edges=np.zeros(len(self.graphs),dtype=int)\n",
    "#     for i in range(len(self.graphs)):\n",
    "#       num_edges[i]=self.graphs[i].graph.number_of_edges()\n",
    "#       self.gt_accept, self.gt_alias=create_alias_table(pow(num_edges,self.args.power)/sum(pow(num_edges,self.args.power)))\n",
    "#       self.gt_accept, self.gt_alias=create_alias_table(num_edges/sum(num_edges))\n",
    "      \n",
    "#   def train(self):\n",
    "#     self.model.compile(optimizer=RMSprop(learning_rate=0.001),loss=self.line_loss)\n",
    "#     batch_size=self.args.num_group*(1+self.args.neg_ratio)\n",
    "#     self.get_graph_sampling_table()\n",
    "    \n",
    "#     for iteration in range(self.args.T):\n",
    "#       if iteration%100==0:\n",
    "#         verbose=1\n",
    "#       else:\n",
    "#         verbose=0\n",
    "        \n",
    "#       gid=alias_sample(self.gt_accept, self.gt_alias)\n",
    "#       s,d,y=self.graphs[gid].batch_iter()\n",
    "#       self.model.fit(x=[s,d],y=y, batch_size=batch_size,verbose=verbose)\n",
    "\n",
    "  def train(self):\n",
    "    self.model.compile(optimizer=RMSprop(learning_rate=0.001),loss=self.line_loss)\n",
    "    batch_size=self.args.num_group*(1+self.args.neg_ratio)\n",
    "    \n",
    "    for iteration in range(self.args.T):\n",
    "      if iteration%100==0:\n",
    "        verbose=1\n",
    "      else:\n",
    "        verbose=0\n",
    "      for j in range(len(self.graphs)):\n",
    "        s,d,y=self.graphs[j].batch_iter()\n",
    "        self.model.fit(x=[s,d],y=y, batch_size=batch_size,verbose=verbose)\n",
    "      \n",
    "  def get_embeddings(self):\n",
    "    self.embeddings=self.model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_args=dotdict({\n",
    "  'power':0.75,\n",
    "  'embedding_size':100,\n",
    "  'T':10000,\n",
    "  'neg_ratio':5,\n",
    "  'num_group':5,\n",
    "})\n",
    "nNodes=len(ct.node2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "he=HeGraph(ge_args, nNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 665us/step - loss: 0.6925\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.6920\n",
      "1/1 [==============================] - 0s 580us/step - loss: 0.6920\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.6918\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.6942\n",
      "1/1 [==============================] - 0s 577us/step - loss: 0.6930\n",
      "1/1 [==============================] - 0s 712us/step - loss: 0.6485\n",
      "1/1 [==============================] - 0s 620us/step - loss: 0.5857\n",
      "1/1 [==============================] - 0s 519us/step - loss: 0.6030\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.6676\n",
      "1/1 [==============================] - 0s 615us/step - loss: 0.6559\n",
      "1/1 [==============================] - 0s 482us/step - loss: 0.5447\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.5285\n",
      "1/1 [==============================] - 0s 670us/step - loss: 0.2989\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.4879\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.6051\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.5034\n",
      "1/1 [==============================] - 0s 475us/step - loss: 0.3847\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.2206\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.1096\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.1411\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.5362\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.4378\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.4015\n",
      "1/1 [==============================] - 0s 717us/step - loss: 0.2283\n",
      "1/1 [==============================] - 0s 661us/step - loss: 0.0979\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.0531\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.4240\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.4169\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.3184\n",
      "1/1 [==============================] - 0s 540us/step - loss: 0.1445\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.0938\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.1665\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.5182\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.4694\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.3171\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.2250\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0675\n",
      "1/1 [==============================] - 0s 482us/step - loss: 0.0325\n",
      "1/1 [==============================] - 0s 640us/step - loss: 0.5565\n",
      "1/1 [==============================] - 0s 615us/step - loss: 0.4851\n",
      "1/1 [==============================] - 0s 477us/step - loss: 0.3059\n",
      "1/1 [==============================] - 0s 525us/step - loss: 0.1251\n",
      "1/1 [==============================] - 0s 616us/step - loss: 0.0631\n",
      "1/1 [==============================] - 0s 509us/step - loss: 0.0662\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.3786\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.3998\n",
      "1/1 [==============================] - 0s 483us/step - loss: 0.2212\n",
      "1/1 [==============================] - 0s 535us/step - loss: 0.3016\n",
      "1/1 [==============================] - 0s 623us/step - loss: 0.1079\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.0988\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.5867\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.5714\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.1694\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.1969\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0823\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0953\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.3613\n",
      "1/1 [==============================] - 0s 477us/step - loss: 0.4189\n",
      "1/1 [==============================] - 0s 632us/step - loss: 0.0609\n",
      "1/1 [==============================] - 0s 663us/step - loss: 0.2307\n",
      "1/1 [==============================] - 0s 483us/step - loss: 0.0449\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0615\n",
      "1/1 [==============================] - 0s 667us/step - loss: 0.4120\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.5303\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.1691\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.2301\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.0358\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.1512\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.6500\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.6605\n",
      "1/1 [==============================] - 0s 482us/step - loss: 0.0773\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.1359\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.0157\n",
      "1/1 [==============================] - 0s 526us/step - loss: 0.1516\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.5653\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.2615\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.0872\n",
      "1/1 [==============================] - 0s 535us/step - loss: 0.0654\n",
      "1/1 [==============================] - 0s 647us/step - loss: 0.0231\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.1377\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.3888\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.4005\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.1322\n",
      "1/1 [==============================] - 0s 664us/step - loss: 0.0946\n",
      "1/1 [==============================] - 0s 644us/step - loss: 0.1360\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0922\n",
      "1/1 [==============================] - 0s 509us/step - loss: 0.5786\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.4836\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.0639\n",
      "1/1 [==============================] - 0s 529us/step - loss: 0.1018\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.0020\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.1440\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.4800\n",
      "1/1 [==============================] - 0s 471us/step - loss: 0.2377\n",
      "1/1 [==============================] - 0s 478us/step - loss: 0.2140\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.0870\n",
      "1/1 [==============================] - 0s 625us/step - loss: 0.0050\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.0540\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.4892\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.3272\n",
      "1/1 [==============================] - 0s 659us/step - loss: 0.0698\n",
      "1/1 [==============================] - 0s 660us/step - loss: 0.4343\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.0807\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0658\n",
      "1/1 [==============================] - 0s 575us/step - loss: 0.3484\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.4162\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.1621\n",
      "1/1 [==============================] - 0s 556us/step - loss: 0.3084\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.1614\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.0498\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.6096\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.2950\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.1245\n",
      "1/1 [==============================] - 0s 646us/step - loss: 0.1339\n",
      "1/1 [==============================] - 0s 591us/step - loss: 0.1120\n",
      "1/1 [==============================] - 0s 630us/step - loss: 0.0603\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.3367\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.2548\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 521us/step - loss: 0.1138\n",
      "1/1 [==============================] - 0s 660us/step - loss: 0.0435\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.0265\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.3721\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.4221\n",
      "1/1 [==============================] - 0s 476us/step - loss: 0.0471\n",
      "1/1 [==============================] - 0s 559us/step - loss: 0.2058\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.0783\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.0241\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.3734\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.3143\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.0319\n",
      "1/1 [==============================] - 0s 524us/step - loss: 0.0948\n",
      "1/1 [==============================] - 0s 630us/step - loss: 0.1144\n",
      "1/1 [==============================] - 0s 519us/step - loss: 0.2360\n",
      "1/1 [==============================] - 0s 541us/step - loss: 0.8922\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.4739\n",
      "1/1 [==============================] - 0s 477us/step - loss: 0.1173\n",
      "1/1 [==============================] - 0s 645us/step - loss: 0.1030\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.1061\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.0661\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.4288\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.1139\n",
      "1/1 [==============================] - 0s 644us/step - loss: 0.0895\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.2253\n",
      "1/1 [==============================] - 0s 671us/step - loss: 0.0535\n",
      "1/1 [==============================] - 0s 525us/step - loss: 0.1202\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.3759\n",
      "1/1 [==============================] - 0s 652us/step - loss: 0.2957\n",
      "1/1 [==============================] - 0s 598us/step - loss: 0.0124\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.1928\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.2070\n",
      "1/1 [==============================] - 0s 664us/step - loss: 0.0539\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.4486\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.3583\n",
      "1/1 [==============================] - 0s 476us/step - loss: 0.0139\n",
      "1/1 [==============================] - 0s 722us/step - loss: 0.0748\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.1233\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.0791\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.3791\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.3844\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.0280\n",
      "1/1 [==============================] - 0s 531us/step - loss: 0.1356\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.0710\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.0207\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.5431\n",
      "1/1 [==============================] - 0s 495us/step - loss: 1.1741\n",
      "1/1 [==============================] - 0s 656us/step - loss: 0.0241\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.0812\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.1735\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.0894\n",
      "1/1 [==============================] - 0s 537us/step - loss: 0.8274\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.2422\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.0324\n",
      "1/1 [==============================] - 0s 541us/step - loss: 0.3321\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.0082\n",
      "1/1 [==============================] - 0s 642us/step - loss: 0.0459\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.5499\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.2449\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.0096\n",
      "1/1 [==============================] - 0s 526us/step - loss: 0.3003\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0409\n",
      "1/1 [==============================] - 0s 707us/step - loss: 0.0632\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.4940\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.2694\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.0745\n",
      "1/1 [==============================] - 0s 661us/step - loss: 0.0630\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.0031\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.1000\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.5439\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.2753\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.0352\n",
      "1/1 [==============================] - 0s 530us/step - loss: 0.3508\n",
      "1/1 [==============================] - 0s 528us/step - loss: 0.1579\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.0118\n",
      "1/1 [==============================] - 0s 526us/step - loss: 0.6933\n",
      "1/1 [==============================] - 0s 529us/step - loss: 0.1192\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.0502\n",
      "1/1 [==============================] - 0s 541us/step - loss: 0.1746\n",
      "1/1 [==============================] - 0s 687us/step - loss: 0.4106\n",
      "1/1 [==============================] - 0s 549us/step - loss: 0.0100\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.3256\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.2211\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0114\n",
      "1/1 [==============================] - 0s 527us/step - loss: 0.0477\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.0193\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.0967\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.3529\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.4973\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.0054\n",
      "1/1 [==============================] - 0s 589us/step - loss: 0.1218\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.3046\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.0229\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.3110\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.3906\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.0353\n",
      "1/1 [==============================] - 0s 659us/step - loss: 0.1822\n",
      "1/1 [==============================] - 0s 618us/step - loss: 5.0068e-07\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.0528\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.4229\n",
      "1/1 [==============================] - 0s 531us/step - loss: 1.1861\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0218\n",
      "1/1 [==============================] - 0s 673us/step - loss: 0.0572\n",
      "1/1 [==============================] - 0s 630us/step - loss: 0.1920\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.1466\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.4496\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.2814\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.0657\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.3995\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.0114\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.0278\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.3220\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.7134\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.0184\n",
      "1/1 [==============================] - 0s 643us/step - loss: 0.1337\n",
      "1/1 [==============================] - 0s 541us/step - loss: 0.0943\n",
      "1/1 [==============================] - 0s 541us/step - loss: 0.0510\n",
      "1/1 [==============================] - 0s 544us/step - loss: 0.4181\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.1399\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 746us/step - loss: 0.1816\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.0726\n",
      "1/1 [==============================] - 0s 526us/step - loss: 0.0442\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.4335\n",
      "1/1 [==============================] - 0s 638us/step - loss: 0.1564\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.0054\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.1192\n",
      "1/1 [==============================] - 0s 641us/step - loss: 0.2777\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0638\n",
      "1/1 [==============================] - 0s 520us/step - loss: 0.6841\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.6063\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.0205\n",
      "1/1 [==============================] - 0s 534us/step - loss: 0.1097\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.1301\n",
      "1/1 [==============================] - 0s 527us/step - loss: 0.1179\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.4939\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.0717\n",
      "1/1 [==============================] - 0s 528us/step - loss: 0.0054\n",
      "1/1 [==============================] - 0s 525us/step - loss: 0.5003\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.1188\n",
      "1/1 [==============================] - 0s 558us/step - loss: 0.0016\n",
      "1/1 [==============================] - 0s 647us/step - loss: 0.7490\n",
      "1/1 [==============================] - 0s 635us/step - loss: 0.5389\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.0066\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.1512\n",
      "1/1 [==============================] - 0s 653us/step - loss: 0.0036\n",
      "1/1 [==============================] - 0s 550us/step - loss: 0.0517\n",
      "1/1 [==============================] - 0s 634us/step - loss: 0.2552\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.2914\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.0040\n",
      "1/1 [==============================] - 0s 697us/step - loss: 0.0445\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.2902\n",
      "1/1 [==============================] - 0s 550us/step - loss: 0.1314\n",
      "1/1 [==============================] - 0s 532us/step - loss: 0.3399\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.0895\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0048\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.0379\n",
      "1/1 [==============================] - 0s 632us/step - loss: 0.0051\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.3005\n",
      "1/1 [==============================] - 0s 660us/step - loss: 0.4844\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.4731\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.0550\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.0936\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.4275\n",
      "1/1 [==============================] - 0s 514us/step - loss: 0.0486\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.3861\n",
      "1/1 [==============================] - 0s 641us/step - loss: 0.0937\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.0031\n",
      "1/1 [==============================] - 0s 537us/step - loss: 0.1501\n",
      "1/1 [==============================] - 0s 616us/step - loss: 0.0015\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0556\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.2761\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.1575\n",
      "1/1 [==============================] - 0s 471us/step - loss: 0.0116\n",
      "1/1 [==============================] - 0s 640us/step - loss: 0.1285\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.0468\n",
      "1/1 [==============================] - 0s 559us/step - loss: 0.1825\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.4624\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.2709\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.0110\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.1842\n",
      "1/1 [==============================] - 0s 536us/step - loss: 0.0020\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.0109\n",
      "1/1 [==============================] - 0s 669us/step - loss: 0.4091\n",
      "1/1 [==============================] - 0s 568us/step - loss: 0.0641\n",
      "1/1 [==============================] - 0s 626us/step - loss: 0.0019\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.4305\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.0137\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.0607\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.3729\n",
      "1/1 [==============================] - 0s 483us/step - loss: 0.1815\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.0077\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.5062\n",
      "1/1 [==============================] - 0s 620us/step - loss: 0.1341\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.1544\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.3689\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.1929\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.0025\n",
      "1/1 [==============================] - 0s 557us/step - loss: 0.6187\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.2849\n",
      "1/1 [==============================] - 0s 520us/step - loss: 0.0546\n",
      "1/1 [==============================] - 0s 543us/step - loss: 0.3361\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.5937\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.0018\n",
      "1/1 [==============================] - 0s 550us/step - loss: 0.1964\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.2707\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0318\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.5839\n",
      "1/1 [==============================] - 0s 873us/step - loss: 0.2239\n",
      "1/1 [==============================] - 0s 609us/step - loss: 0.0759\n",
      "1/1 [==============================] - 0s 673us/step - loss: 0.2166\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.0129\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.0548\n",
      "1/1 [==============================] - 0s 531us/step - loss: 0.2615\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.4904\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.0116\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.0321\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.1481\n",
      "1/1 [==============================] - 0s 710us/step - loss: 0.0137\n",
      "1/1 [==============================] - 0s 514us/step - loss: 0.6336\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.4770\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.0087\n",
      "1/1 [==============================] - 0s 571us/step - loss: 0.3722\n",
      "1/1 [==============================] - 0s 679us/step - loss: 0.1056\n",
      "1/1 [==============================] - 0s 685us/step - loss: 0.2119\n",
      "1/1 [==============================] - 0s 519us/step - loss: 0.4637\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.4059\n",
      "1/1 [==============================] - 0s 482us/step - loss: 0.0309\n",
      "1/1 [==============================] - 0s 524us/step - loss: 0.1501\n",
      "1/1 [==============================] - 0s 632us/step - loss: 0.4671\n",
      "1/1 [==============================] - 0s 640us/step - loss: 0.0963\n",
      "1/1 [==============================] - 0s 525us/step - loss: 0.4884\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.9763\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.0175\n",
      "1/1 [==============================] - 0s 528us/step - loss: 0.2197\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.1685\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.0603\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.3189\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.4965\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 528us/step - loss: 0.0963\n",
      "1/1 [==============================] - 0s 659us/step - loss: 0.2690\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.0046\n",
      "1/1 [==============================] - 0s 692us/step - loss: 0.2687\n",
      "1/1 [==============================] - 0s 631us/step - loss: 0.1360\n",
      "1/1 [==============================] - 0s 623us/step - loss: 0.0114\n",
      "1/1 [==============================] - 0s 526us/step - loss: 0.2585\n",
      "1/1 [==============================] - 0s 622us/step - loss: 0.1439\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.1359\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.4461\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.1858\n",
      "1/1 [==============================] - 0s 615us/step - loss: 0.0110\n",
      "1/1 [==============================] - 0s 530us/step - loss: 0.2847\n",
      "1/1 [==============================] - 0s 517us/step - loss: 2.8058e-04\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.0083\n",
      "1/1 [==============================] - 0s 527us/step - loss: 0.2744\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0399\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.0098\n",
      "1/1 [==============================] - 0s 685us/step - loss: 0.2350\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.0020\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.0457\n",
      "1/1 [==============================] - 0s 664us/step - loss: 0.5030\n",
      "1/1 [==============================] - 0s 611us/step - loss: 0.1960\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.0118\n",
      "1/1 [==============================] - 0s 520us/step - loss: 0.0781\n",
      "1/1 [==============================] - 0s 630us/step - loss: 0.0340\n",
      "1/1 [==============================] - 0s 645us/step - loss: 0.0667\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.4285\n",
      "1/1 [==============================] - 0s 482us/step - loss: 0.1089\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.0026\n",
      "1/1 [==============================] - 0s 559us/step - loss: 0.2638\n",
      "1/1 [==============================] - 0s 535us/step - loss: 0.1257\n",
      "1/1 [==============================] - 0s 620us/step - loss: 0.1286\n",
      "1/1 [==============================] - 0s 615us/step - loss: 0.4352\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.1338\n",
      "1/1 [==============================] - 0s 611us/step - loss: 0.0116\n",
      "1/1 [==============================] - 0s 528us/step - loss: 0.5292\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.3762\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.1399\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.3364\n",
      "1/1 [==============================] - 0s 632us/step - loss: 0.7934\n",
      "1/1 [==============================] - 0s 660us/step - loss: 0.0444\n",
      "1/1 [==============================] - 0s 533us/step - loss: 0.1348\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.7341\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.1061\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.4996\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.2297\n",
      "1/1 [==============================] - 0s 477us/step - loss: 0.0282\n",
      "1/1 [==============================] - 0s 650us/step - loss: 0.3540\n",
      "1/1 [==============================] - 0s 485us/step - loss: 0.1238\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.0311\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.3874\n",
      "1/1 [==============================] - 0s 710us/step - loss: 0.1311\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.0018\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.1476\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.0014\n",
      "1/1 [==============================] - 0s 519us/step - loss: 0.0554\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.4366\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.1116\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.0025\n",
      "1/1 [==============================] - 0s 517us/step - loss: 0.6491\n",
      "1/1 [==============================] - 0s 638us/step - loss: 0.2307\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.0648\n",
      "1/1 [==============================] - 0s 648us/step - loss: 0.4439\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.1196\n",
      "1/1 [==============================] - 0s 567us/step - loss: 0.0097\n",
      "1/1 [==============================] - 0s 534us/step - loss: 0.2814\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.0022\n",
      "1/1 [==============================] - 0s 514us/step - loss: 0.0207\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.4889\n",
      "1/1 [==============================] - 0s 502us/step - loss: 1.1495\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.0565\n",
      "1/1 [==============================] - 0s 519us/step - loss: 0.3103\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.0062\n",
      "1/1 [==============================] - 0s 491us/step - loss: 0.1490\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.3628\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.1812\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.0019\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.2012\n",
      "1/1 [==============================] - 0s 615us/step - loss: 0.1776\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.0676\n",
      "1/1 [==============================] - 0s 505us/step - loss: 0.4164\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.0792\n",
      "1/1 [==============================] - 0s 472us/step - loss: 0.0034\n",
      "1/1 [==============================] - 0s 538us/step - loss: 0.3226\n",
      "1/1 [==============================] - 0s 666us/step - loss: 0.2305\n",
      "1/1 [==============================] - 0s 483us/step - loss: 0.1031\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.4110\n",
      "1/1 [==============================] - 0s 614us/step - loss: 0.1066\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0064\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.3392\n",
      "1/1 [==============================] - 0s 491us/step - loss: 5.3916e-04\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0903\n",
      "1/1 [==============================] - 0s 487us/step - loss: 0.5210\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.2374\n",
      "1/1 [==============================] - 0s 633us/step - loss: 0.0787\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.5123\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.0775\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.0721\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.2887\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.1924\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.0042\n",
      "1/1 [==============================] - 0s 551us/step - loss: 0.7440\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.1741\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.0040\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.5614\n",
      "1/1 [==============================] - 0s 485us/step - loss: 0.4837\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.0205\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.0848\n",
      "1/1 [==============================] - 0s 673us/step - loss: 0.3415\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.2562\n",
      "1/1 [==============================] - 0s 509us/step - loss: 0.2503\n",
      "1/1 [==============================] - 0s 662us/step - loss: 0.1683\n",
      "1/1 [==============================] - 0s 476us/step - loss: 0.0176\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.3849\n",
      "1/1 [==============================] - 0s 480us/step - loss: 0.6108\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.0637\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.4123\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.5103\n",
      "1/1 [==============================] - 0s 526us/step - loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 511us/step - loss: 0.5927\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.0144\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.2163\n",
      "1/1 [==============================] - 0s 573us/step - loss: 0.3725\n",
      "1/1 [==============================] - 0s 632us/step - loss: 0.9035\n",
      "1/1 [==============================] - 0s 625us/step - loss: 0.0055\n",
      "1/1 [==============================] - 0s 530us/step - loss: 0.1376\n",
      "1/1 [==============================] - 0s 523us/step - loss: 0.0283\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.0131\n",
      "1/1 [==============================] - 0s 501us/step - loss: 0.3795\n",
      "1/1 [==============================] - 0s 620us/step - loss: 0.1419\n",
      "1/1 [==============================] - 0s 625us/step - loss: 0.0029\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.2184\n",
      "1/1 [==============================] - 0s 630us/step - loss: 0.0208\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0214\n",
      "1/1 [==============================] - 0s 524us/step - loss: 0.3340\n",
      "1/1 [==============================] - 0s 485us/step - loss: 0.0319\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.0189\n",
      "1/1 [==============================] - 0s 534us/step - loss: 0.0763\n",
      "1/1 [==============================] - 0s 465us/step - loss: 6.8993e-04\n",
      "1/1 [==============================] - 0s 495us/step - loss: 4.4128e-04\n",
      "1/1 [==============================] - 0s 672us/step - loss: 0.5657\n",
      "1/1 [==============================] - 0s 476us/step - loss: 0.1203\n",
      "1/1 [==============================] - 0s 482us/step - loss: 0.0057\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.0215\n",
      "1/1 [==============================] - 0s 525us/step - loss: 7.6152e-04\n",
      "1/1 [==============================] - 0s 623us/step - loss: 0.0302\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.3373\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.7430\n",
      "1/1 [==============================] - 0s 474us/step - loss: 0.0580\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.4243\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.2566\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.2467\n",
      "1/1 [==============================] - 0s 520us/step - loss: 0.2243\n",
      "1/1 [==============================] - 0s 483us/step - loss: 0.3868\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.0448\n",
      "1/1 [==============================] - 0s 537us/step - loss: 0.3625\n",
      "1/1 [==============================] - 0s 652us/step - loss: 0.1033\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.0040\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.5554\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.3178\n",
      "1/1 [==============================] - 0s 497us/step - loss: 0.0608\n",
      "1/1 [==============================] - 0s 577us/step - loss: 0.0843\n",
      "1/1 [==============================] - 0s 488us/step - loss: 0.1099\n",
      "1/1 [==============================] - 0s 676us/step - loss: 0.0399\n",
      "1/1 [==============================] - 0s 637us/step - loss: 0.2656\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.3986\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.0444\n",
      "1/1 [==============================] - 0s 583us/step - loss: 0.2272\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.1004\n",
      "1/1 [==============================] - 0s 509us/step - loss: 0.0104\n",
      "1/1 [==============================] - 0s 654us/step - loss: 0.4970\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.0566\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.0036\n",
      "1/1 [==============================] - 0s 693us/step - loss: 0.2359\n",
      "1/1 [==============================] - 0s 622us/step - loss: 0.0108\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.1043\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.3134\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.0312\n",
      "1/1 [==============================] - 0s 485us/step - loss: 0.0031\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.6335\n",
      "1/1 [==============================] - 0s 485us/step - loss: 0.2563\n",
      "1/1 [==============================] - 0s 499us/step - loss: 0.1364\n",
      "1/1 [==============================] - 0s 680us/step - loss: 0.3582\n",
      "1/1 [==============================] - 0s 617us/step - loss: 0.1463\n",
      "1/1 [==============================] - 0s 502us/step - loss: 0.0066\n",
      "1/1 [==============================] - 0s 527us/step - loss: 0.0226\n",
      "1/1 [==============================] - 0s 628us/step - loss: 0.3908\n",
      "1/1 [==============================] - 0s 643us/step - loss: 0.1193\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.4847\n",
      "1/1 [==============================] - 0s 498us/step - loss: 0.1749\n",
      "1/1 [==============================] - 0s 518us/step - loss: 0.0031\n",
      "1/1 [==============================] - 0s 529us/step - loss: 0.4091\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.0394\n",
      "1/1 [==============================] - 0s 642us/step - loss: 0.0694\n",
      "1/1 [==============================] - 0s 511us/step - loss: 0.2438\n",
      "1/1 [==============================] - 0s 493us/step - loss: 0.0908\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.0332\n",
      "1/1 [==============================] - 0s 533us/step - loss: 0.0293\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.2507\n",
      "1/1 [==============================] - 0s 500us/step - loss: 0.0623\n",
      "1/1 [==============================] - 0s 504us/step - loss: 0.4261\n",
      "1/1 [==============================] - 0s 481us/step - loss: 0.3218\n",
      "1/1 [==============================] - 0s 492us/step - loss: 0.0094\n",
      "1/1 [==============================] - 0s 681us/step - loss: 0.1026\n",
      "1/1 [==============================] - 0s 463us/step - loss: 0.0116\n",
      "1/1 [==============================] - 0s 503us/step - loss: 0.0323\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.3392\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.1495\n",
      "1/1 [==============================] - 0s 516us/step - loss: 0.0104\n",
      "1/1 [==============================] - 0s 514us/step - loss: 0.5312\n",
      "1/1 [==============================] - 0s 498us/step - loss: 7.7092e-04\n",
      "1/1 [==============================] - 0s 522us/step - loss: 0.0344\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.3686\n",
      "1/1 [==============================] - 0s 484us/step - loss: 0.0768\n",
      "1/1 [==============================] - 0s 479us/step - loss: 0.0676\n",
      "1/1 [==============================] - 0s 524us/step - loss: 0.1797\n",
      "1/1 [==============================] - 0s 469us/step - loss: 7.4207e-05\n",
      "1/1 [==============================] - 0s 645us/step - loss: 0.0330\n",
      "1/1 [==============================] - 0s 533us/step - loss: 0.4198\n",
      "1/1 [==============================] - 0s 616us/step - loss: 0.0544\n",
      "1/1 [==============================] - 0s 494us/step - loss: 0.0024\n",
      "1/1 [==============================] - 0s 644us/step - loss: 0.4798\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0337\n",
      "1/1 [==============================] - 0s 512us/step - loss: 0.0776\n",
      "1/1 [==============================] - 0s 521us/step - loss: 0.4216\n",
      "1/1 [==============================] - 0s 489us/step - loss: 0.0374\n",
      "1/1 [==============================] - 0s 583us/step - loss: 0.0216\n",
      "1/1 [==============================] - 0s 520us/step - loss: 0.1577\n",
      "1/1 [==============================] - 0s 526us/step - loss: 3.6983e-05\n",
      "1/1 [==============================] - 0s 548us/step - loss: 0.0101\n",
      "1/1 [==============================] - 0s 532us/step - loss: 0.3322\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.6591\n",
      "1/1 [==============================] - 0s 495us/step - loss: 0.0378\n",
      "1/1 [==============================] - 0s 543us/step - loss: 0.5119\n",
      "1/1 [==============================] - 0s 496us/step - loss: 0.2574\n",
      "1/1 [==============================] - 0s 515us/step - loss: 0.2397\n",
      "1/1 [==============================] - 0s 509us/step - loss: 0.4637\n",
      "1/1 [==============================] - 0s 490us/step - loss: 0.4464\n",
      "1/1 [==============================] - 0s 486us/step - loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start=time()\n",
    "he.train()\n",
    "runtime=(time()-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "he.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43374\n",
      "3696\n",
      "17082\n",
      "22772\n",
      "558\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(he.graphs)):\n",
    "  print(he.graphs[i].graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.106772216161094"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class Evaluator:\n",
    "  def __init__(self,test,ct,predict_type,N):\n",
    "    self.test=test[['Community Area', 'hour', 'text']].values.tolist()\n",
    "    self.ct=ct\n",
    "    self.predict_type=predict_type\n",
    "    self.N=N\n",
    "    self.batch_size=1000\n",
    "    self.test=self.to_number(self.test)\n",
    "  \n",
    "  def lookup(self, g):\n",
    "    '''\n",
    "    input: a crime incident record, predict type\n",
    "    return: x, y, candidate pool\n",
    "    '''\n",
    "    r, h, w=g[0], g[1], g[2]\n",
    "    if self.predict_type=='w':\n",
    "      x=[r]+[h]\n",
    "      y=w\n",
    "      cand_pool=[self.ct.node2idx[w] for w in self.ct.words]\n",
    "    if self.predict_type=='r':\n",
    "#       x=[h]+np.random.choice(w,self.nWords,replace=False).tolist()\n",
    "      x=[h]+w\n",
    "      y=[r]\n",
    "      cand_pool=[self.ct.node2idx[r] for r in self.ct.regions]\n",
    "    if self.predict_type=='h':\n",
    "      x=[r]+w\n",
    "      y=[h]\n",
    "      cand_pool=[self.ct.node2idx[h] for h in self.ct.hours]\n",
    "    return x,y,cand_pool\n",
    "    \n",
    "\n",
    "  def generate_group(self, inc):\n",
    "    '''\n",
    "    input: a criminal incident record\n",
    "    return: a group (positive + negative examples)\n",
    "    '''\n",
    "    # get x,y\n",
    "    x, y, cand_pool=self.lookup(inc)\n",
    "\n",
    "    # generate positive examples\n",
    "    labels=[1]*len(y)\n",
    "    \n",
    "    # generate negative examples\n",
    "    while len(y)<self.N:\n",
    "      neg=np.random.choice(cand_pool)\n",
    "      if neg not in y:\n",
    "        y.append(neg)\n",
    "        labels.append(0)\n",
    "    \n",
    "    g=list(zip([x]*self.N, y, labels))\n",
    "              \n",
    "    return g\n",
    "\n",
    "  def reserve_example(self, inc):\n",
    "    '''\n",
    "    discard incident record whose nodes not occur in train set\n",
    "    return: True or False\n",
    "    '''\n",
    "    if inc[0] not in self.ct.node2idx:\n",
    "      return False\n",
    "    if inc[1] not in self.ct.node2idx:\n",
    "      return False\n",
    "    for w in inc[2]:\n",
    "      if w not in self.ct.node2idx:\n",
    "        return False\n",
    "    return True\n",
    "      \n",
    "    \n",
    "  def to_number(self, data):\n",
    "    '''\n",
    "    input: examples set\n",
    "    convert each word to number\n",
    "    '''\n",
    "    lst=[]\n",
    "    for i in range(len(data)):\n",
    "      if self.reserve_example(data[i]):\n",
    "        x=[self.ct.node2idx[data[i][0]], self.ct.node2idx[data[i][1]], [self.ct.node2idx[w] for w in data[i][2]]]\n",
    "        lst.append(x)  \n",
    "    return lst\n",
    "\n",
    "  def generate_test_groups(self):\n",
    "    gs=[]\n",
    "    for inc in self.test:\n",
    "      g=self.generate_group(inc)\n",
    "      gs.extend(g)\n",
    "    return gs\n",
    "\n",
    "  def cos_sim(self, a, b):\n",
    "    return np.sum(a*b, axis=1)/(np.linalg.norm(a, axis=1)*np.linalg.norm(b,axis=1))\n",
    "    \n",
    "  def batch_sim(self, emb_lst, x, y):\n",
    "\n",
    "    y_emb=np.array([emb_lst[u] for u in y])\n",
    "    sim=np.zeros((x.shape[1],x.shape[0]))\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "      x_emb=np.array([emb_lst[u] for u in x[:,i]])\n",
    "      sim[i]=self.cos_sim(x_emb,y_emb)\n",
    " \n",
    "    return np.mean(sim, axis=0)\n",
    "  \n",
    "  def baseline(self, gs):\n",
    "    ranks=[]\n",
    "    x, y, label=list(zip(*gs))\n",
    "    for i in range(0, len(label), self.N):\n",
    "      l=np.array(label[i:i+self.N])\n",
    "      x_inter=set.intersection(*list(map(lambda h: self.ct.node2inc[h],x[i])))\n",
    "      freq=list(map(lambda h: len(x_inter.intersection(self.ct.node2inc[h])), y[i:i+self.N]))\n",
    "      ranks.append(l[np.argsort(freq)[::-1]])\n",
    "    return np.array(ranks)\n",
    "\n",
    "  def get_ranks(self, gs, emb_lst):\n",
    "    ranks=[]\n",
    "    sims=[]\n",
    "    x, y, label=list(zip(*gs))\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    label=np.array(label)\n",
    "\n",
    "    for i in range(0, len(y), self.batch_size):\n",
    "      end=i+self.batch_size\n",
    "      sim=self.batch_sim(emb_lst, x[i:end], y[i:end])\n",
    "      sims.extend(sim.tolist())\n",
    "    \n",
    "    for i in range(0, len(sims), self.N):\n",
    "      l=label[i:i+self.N]\n",
    "      ranks.append(l[np.argsort(sims[i:i+self.N])[::-1]])\n",
    "\n",
    "    return np.array(ranks)\n",
    "  \n",
    "  def F1_score(self, ranks,k=10):\n",
    "    '''\n",
    "    for labels prediction\n",
    "    '''\n",
    "    relevant=np.sum(ranks[:,:k], axis=1)\n",
    "    recall=relevant/np.sum(ranks,axis=1)\n",
    "    precision=relevant/k\n",
    "    meanF1=np.mean(2*precision*recall/(precision+recall))\n",
    "    return meanF1\n",
    "\n",
    "  def MRR(self,ranks):\n",
    "    '''\n",
    "    for location and labels prediction\n",
    "    '''\n",
    "    pos=np.argmax(ranks>0, axis=1)+1\n",
    "    mrr=np.mean(1/pos)\n",
    "    \n",
    "    return mrr\n",
    "  \n",
    "  def MAP(self, ranks):\n",
    "    aps=[]\n",
    "    for i in range(len(ranks)):\n",
    "      recall_pos=np.where(ranks[i]==1)[0]+1\n",
    "      ap=np.mean((np.arange(len(recall_pos))+1)/recall_pos)\n",
    "      aps.append(ap)\n",
    "      \n",
    "    return np.mean(aps)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew=Evaluator(test, ct, predict_type='w', N=20)\n",
    "gs_w=ew.generate_test_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "er=Evaluator(test, ct, predict_type='r', N=10)\n",
    "gs_r=er.generate_test_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eh=Evaluator(test, ct, predict_type='h', N=10)\n",
    "gs_h=eh.generate_test_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_w_ranks=ew.baseline(gs_w)\n",
    "ns_w_mrr=ew.MRR(ns_w_ranks)\n",
    "ns_w_map=ew.MAP(ns_w_ranks)\n",
    "print('ns_w_mrr={}'.format(ns_w_mrr))\n",
    "print('ns_w_map={}'.format(ns_w_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns_r_mrr=0.4479534001279555\n",
      "ns_r_map=0.4479534001279555\n"
     ]
    }
   ],
   "source": [
    "ns_r_ranks=er.baseline(gs_r)\n",
    "ns_r_mrr=er.MRR(ns_r_ranks)\n",
    "ns_r_map=er.MAP(ns_r_ranks)\n",
    "print('ns_r_mrr={}'.format(ns_r_mrr))\n",
    "print('ns_r_map={}'.format(ns_r_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns_h_mrr=0.3179829099528738\n",
      "ns_h_map=0.3179829099528738\n"
     ]
    }
   ],
   "source": [
    "ns_h_ranks=eh.baseline(gs_h)\n",
    "ns_h_mrr=eh.MRR(ns_h_ranks)\n",
    "ns_h_map=eh.MAP(ns_h_ranks)\n",
    "print('ns_h_mrr={}'.format(ns_h_mrr))\n",
    "print('ns_h_map={}'.format(ns_h_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge_w_mrr=0.8840342486300676\n",
      "ge_w_map=0.7331176499544174\n"
     ]
    }
   ],
   "source": [
    "ge_w_ranks=ew.get_ranks(gs_w, he.embeddings)\n",
    "ge_w_mrr=ew.MRR(ge_w_ranks)\n",
    "ge_w_map=ew.MAP(ge_w_ranks)\n",
    "print('ge_w_mrr={}'.format(ge_w_mrr))\n",
    "print('ge_w_map={}'.format(ge_w_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge_r_mrr=0.41747027987171725\n",
      "ge_r_map=0.41747027987171725\n"
     ]
    }
   ],
   "source": [
    "ge_r_ranks=er.get_ranks(gs_r, he.embeddings)\n",
    "ge_r_mrr=er.MRR(ge_r_ranks)\n",
    "ge_r_map=er.MAP(ge_r_ranks)\n",
    "print('ge_r_mrr={}'.format(ge_r_mrr))\n",
    "print('ge_r_map={}'.format(ge_r_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ge_h_mrr=0.2759361753729986\n",
      "ge_h_map=0.2759361753729986\n"
     ]
    }
   ],
   "source": [
    "ge_h_ranks=eh.get_ranks(gs_h, he.embeddings)\n",
    "ge_h_mrr=eh.MRR(ge_h_ranks)\n",
    "ge_h_map=eh.MAP(ge_h_ranks)\n",
    "print('ge_h_mrr={}'.format(ge_h_mrr))\n",
    "print('ge_h_map={}'.format(ge_h_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td_w_mrr=0.8651352129521664\n",
      "td_w_map=0.7032797058028452\n"
     ]
    }
   ],
   "source": [
    "td_w_ranks=ew.get_ranks(gs_w, td.embeddings)\n",
    "td_w_mrr=ew.MRR(td_w_ranks)\n",
    "td_w_map=ew.MAP(td_w_ranks)\n",
    "print('td_w_mrr={}'.format(td_w_mrr))\n",
    "print('td_w_map={}'.format(td_w_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td_r_mrr=0.4457367827745857\n",
      "td_r_map=0.4457367827745857\n"
     ]
    }
   ],
   "source": [
    "td_r_ranks=er.get_ranks(gs_r, td.embeddings)\n",
    "td_r_mrr=er.MRR(td_r_ranks)\n",
    "td_r_map=er.MAP(td_r_ranks)\n",
    "print('td_r_mrr={}'.format(td_r_mrr))\n",
    "print('td_r_map={}'.format(td_r_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "td_r_mrr=0.35759084735886265\n",
      "td_r_map=0.35759084735886265\n"
     ]
    }
   ],
   "source": [
    "td_h_ranks=eh.get_ranks(gs_h, td.embeddings)\n",
    "td_h_mrr=eh.MRR(td_h_ranks)\n",
    "td_h_map=eh.MAP(td_h_ranks)\n",
    "print('td_r_mrr={}'.format(td_h_mrr))\n",
    "print('td_r_map={}'.format(td_h_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd_w_mrr=0.5501755237735296\n",
      "sd_w_map=0.42058169107434085\n"
     ]
    }
   ],
   "source": [
    "sd_w_ranks=ew.get_ranks(gs_w, sd.embeddings)\n",
    "sd_w_mrr=ew.MRR(sd_w_ranks)\n",
    "sd_w_map=ew.MAP(sd_w_ranks)\n",
    "print('sd_w_mrr={}'.format(sd_w_mrr))\n",
    "print('sd_w_map={}'.format(sd_w_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd_r_mrr=0.38972503943472275\n",
      "sd_r_map=0.38972503943472275\n"
     ]
    }
   ],
   "source": [
    "sd_r_ranks=er.get_ranks(gs_r, sd.embeddings)\n",
    "sd_r_mrr=er.MRR(sd_r_ranks)\n",
    "sd_r_map=er.MAP(sd_r_ranks)\n",
    "print('sd_r_mrr={}'.format(sd_r_mrr))\n",
    "print('sd_r_map={}'.format(sd_r_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd_r_mrr=0.32459267364464595\n",
      "sd_r_map=0.32459267364464595\n"
     ]
    }
   ],
   "source": [
    "sd_h_ranks=eh.get_ranks(gs_h, sd.embeddings)\n",
    "sd_h_mrr=eh.MRR(sd_h_ranks)\n",
    "sd_h_map=eh.MAP(sd_h_ranks)\n",
    "print('sd_r_mrr={}'.format(sd_h_mrr))\n",
    "print('sd_r_map={}'.format(sd_h_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_ranks=e.get_ranks(gs, sd.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_mrr=e.MRR(sd_ranks)\n",
    "sd_map=e.MAP(sd_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47953113704317607"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30086364067530047"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(ct.df, test_size=0.2)\n",
    "test=test[['Community Area', 'hour', 'text']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=list(map(lambda x: [ct.node2idx[x[0]], ct.node2idx[x[1]], [ct.node2idx[w] for w in x[2]]],test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-7ce62b9919b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "for r, h, ws in test[0]:\n",
    "  print(r, h, ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', 17, {'battery', 'sidewalk', 'simple'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279770"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398847"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ct.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
