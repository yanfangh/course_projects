{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.utils import *\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('wikiQA/WikiQA-train.tsv', sep='\\t')\n",
    "dev=pd.read_csv('wikiQA/WikiQA-dev.tsv', sep='\\t')\n",
    "test=pd.read_csv('wikiQA/WikiQA-test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/vol/home/s2465922/gensim-data/\"\n",
    "file=\"glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\"\n",
    "\n",
    "model_embed = KeyedVectors.load_word2vec_format(folder+file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "  # delete questions without correct answers\n",
    "  ls=df.groupby(['QuestionID'])['Label'].sum()\n",
    "  ind=ls[ls==0].index\n",
    "  df=df.set_index('QuestionID').drop(ind)\n",
    "  return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Seq():\n",
    "  def __init__(self, model, docs, max_sentence_length):\n",
    "    self.model=model\n",
    "    self.docs=docs\n",
    "    self.t=self.tokenizer(docs)\n",
    "    self.maxLen=max_sentence_length\n",
    "\n",
    "  def tokenizer(self,docs):\n",
    "    t=Tokenizer()\n",
    "    t.fit_on_texts(docs)\n",
    "    return t\n",
    "  \n",
    "  def create_padded_sentence(self,sentence):\n",
    "    encoded_sentence=self.t.texts_to_sequences([sentence])\n",
    "    padded_sentence=pad_sequences(encoded_sentence, maxlen=self.maxLen, padding='post')\n",
    "    return padded_sentence[0]\n",
    "  \n",
    "  def create_embedding_matrix(self):\n",
    "    vocab_size=len(self.t.word_index)+1\n",
    "    embedding_matrix=np.zeros((vocab_size, self.model.vector_size))\n",
    "    for word,i in self.t.word_index.items():\n",
    "      if word in self.model.vocab:\n",
    "        embedding_matrix[i]=self.model[word]\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleGenerator():\n",
    "  def __init__(self, nCandidate):\n",
    "    self.nCandidate=nCandidate\n",
    "    \n",
    "  def sample_neg_answers(self, df, QuestionID, nNegs):\n",
    "    neg_as=[]\n",
    "    negs=df[(df['QuestionID']==QuestionID) & (df['Label']==0)]['a_vec'].to_list()\n",
    "    diff=nNegs-len(negs)\n",
    "    if diff<=0:\n",
    "      ind=np.random.choice(len(negs), nNegs, replace=False)\n",
    "      for i in ind:\n",
    "        neg_as.append(negs[i])\n",
    "    else:\n",
    "      neg_as=neg_as+negs\n",
    "      answer_pool=df[df['QuestionID']!=QuestionID]['a_vec'].to_list()\n",
    "      ind=np.random.choice(len(answer_pool),diff,replace=False)\n",
    "      for i in ind:\n",
    "        neg_as.append(answer_pool[i]) \n",
    "    return neg_as\n",
    "      \n",
    "  def create_train_group(self,df):\n",
    "    '''\n",
    "    treat each question with multiples groud truth as multiple groups\n",
    "    '''\n",
    "    \n",
    "    pos_ind=df.loc[df['Label']==1].index\n",
    "    train_gs=[]\n",
    "    for i in pos_ind:\n",
    "      examples=[]\n",
    "      qid, q, p=df.loc[i,['QuestionID','q_vec','a_vec']].to_list()\n",
    "      pos_example=[q, p, int(1)]\n",
    "      examples.append(pos_example)\n",
    "      neg_as=self.sample_neg_answers(df,qid, self.nCandidate)\n",
    "      neg_examples=list(map(lambda n: [q, n, int(0)], neg_as))\n",
    "      examples.extend(neg_examples)\n",
    "      train_gs.append(examples)\n",
    "    return train_gs\n",
    "      \n",
    "  def create_examples(self,gs):\n",
    "    examples=[]\n",
    "    for g in gs:\n",
    "      triplets=[]\n",
    "      q=g[0][0]\n",
    "      p=g[0][1]\n",
    "      for i in range(1,len(g)) :\n",
    "        triplets.append([q,p,g[i][1]])\n",
    "      examples.extend(triplets)\n",
    "    return examples\n",
    "  \n",
    "  def create_test_group(self, df):\n",
    "    '''\n",
    "    treat each question as a group \n",
    "    '''\n",
    "    qids=pd.unique(df['QuestionID']).tolist()\n",
    "    test_gs=[]\n",
    "    for qid in qids:\n",
    "      examples=[]\n",
    "      records=df[(df['QuestionID']==qid) & (df['Label']==1)]\n",
    "      q=records['q_vec'].tolist()[0]\n",
    "      pos_as=records['a_vec'].tolist()\n",
    "      pos_examples=list(map(lambda p: [q, p, int(1)], pos_as))\n",
    "      examples.extend(pos_examples)\n",
    "      neg_as=self.sample_neg_answers(df, qid, self.nCandidate-len(pos_as))\n",
    "      neg_examples=list(map(lambda n: [q, n, int(0)], neg_as))\n",
    "      examples.extend(neg_examples)\n",
    "      test_gs.append(examples)\n",
    "    return test_gs\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=clean(train)\n",
    "dev=clean(dev)\n",
    "test=clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all documents\n",
    "docs=pd.unique(train['Question']).tolist()\n",
    "docs.extend(train['Sentence'].to_list())\n",
    "docs.extend(pd.unique(dev['Question']).tolist())\n",
    "docs.extend(dev['Sentence'].to_list())\n",
    "docs.extend(pd.unique(test['Question']).tolist())\n",
    "docs.extend(test['Sentence'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert word to sequence\n",
    "ws=Word2Seq(model_embed, docs, 40)\n",
    "\n",
    "train['q_vec']=train['Question'].apply(lambda x: ws.create_padded_sentence(x))\n",
    "train['a_vec']=train['Sentence'].apply(lambda x: ws.create_padded_sentence(x))\n",
    "\n",
    "dev['q_vec']=dev['Question'].apply(lambda x: ws.create_padded_sentence(x))\n",
    "dev['a_vec']=dev['Sentence'].apply(lambda x: ws.create_padded_sentence(x))\n",
    "\n",
    "test['q_vec']=test['Question'].apply(lambda x: ws.create_padded_sentence(x))\n",
    "test['a_vec']=test['Sentence'].apply(lambda x: ws.create_padded_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=ExampleGenerator(50)\n",
    "train_gs=G.create_train_group(train)     \n",
    "trainExamples=G.create_examples(train_gs)\n",
    "\n",
    "dev_gs=G.create_train_group(dev)    \n",
    "devExamples=G.create_examples(dev_gs)\n",
    "dev_gs_for_eval=G.create_test_group(dev)  # for evaluation\n",
    "\n",
    "test_gs=G.create_test_group(test)\n",
    "\n",
    "embedding_matrix=ws.create_embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnet:\n",
    "  def __init__(self):\n",
    "    self.embedding_matrix=embedding_matrix\n",
    "    self.vocab_size, self.vec_size=embedding_matrix.shape\n",
    "    self.model=self.build_model()\n",
    "    \n",
    "  \n",
    "  def create_base_network(self):\n",
    "    in_sentence=Input(shape=(max_sentence_length,))\n",
    "    embedding=Embedding(self.vocab_size, self.vec_size, \n",
    "                        weights=[self.embedding_matrix],\n",
    "                        input_length=max_sentence_length,\n",
    "                        trainable=False)(in_sentence)\n",
    "    gru=GRU(100,dropout=0.5,\n",
    "            return_sequences=True,\n",
    "            kernel_initializer='glorot_normal',\n",
    "            kernel_regularizer=keras.regularizers.l2(0.005))(embedding)\n",
    "\n",
    "#     rnn=SimpleRNN(100, dropout=0.5,\n",
    "#             return_sequences=True,\n",
    "#             kernel_initializer='glorot_normal',\n",
    "#             kernel_regularizer=keras.regularizers.l2(0.005))(embedding)\n",
    "    out=GlobalMaxPooling1D()(gru)\n",
    "    return Model(in_sentence, out)\n",
    "  \n",
    "  def build_model(self):\n",
    "    in_q = Input(shape=(max_sentence_length,), name='in_q')\n",
    "    in_pos=Input(shape=(max_sentence_length,), name='in_pos')\n",
    "    in_neg=Input(shape=(max_sentence_length,),name='in_neg')\n",
    "    \n",
    "    self.base_network=self.create_base_network()\n",
    "    q=self.base_network(in_q)\n",
    "    pos=self.base_network(in_pos)\n",
    "    neg=self.base_network(in_neg)\n",
    "\n",
    "    q_pos = Dot(axes=1, normalize=True)([q,pos])\n",
    "    q_neg = Dot(axes=1, normalize=True)([q,neg])\n",
    "    sims=concatenate([q_pos,q_neg])\n",
    "\n",
    "    model = Model(inputs=[in_q, in_pos, in_neg], outputs=sims)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00025),\n",
    "                  loss=self.triplet_loss)\n",
    "\n",
    "    return model\n",
    "    \n",
    "  def triplet_loss(self,y_true,y_pred):\n",
    "    margin=0.2\n",
    "    q_pos_sim, q_neg_sim=y_pred[:,0], y_pred[:,1]\n",
    "    loss = tf.maximum(tf.constant(0.0),tf.constant(margin) - q_pos_sim + q_neg_sim)\n",
    "    return tf.reduce_mean(loss)\n",
    "    \n",
    "  def train(self, trainExamples, devExamples):\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    \n",
    "    qs_train, pos_as_train, neg_as_train = list(zip(*trainExamples))\n",
    "    qs_train=np.array(qs_train)\n",
    "    pos_as_train=np.array(pos_as_train)\n",
    "    neg_as_train=np.array(neg_as_train)\n",
    "    \n",
    "    qs_dev, pos_as_dev, neg_as_dev = list(zip(*devExamples))\n",
    "    qs_dev=np.array(qs_dev)\n",
    "    pos_as_dev=np.array(pos_as_dev)\n",
    "    neg_as_dev=np.array(neg_as_dev)\n",
    "    \n",
    "    out_train=np.zeros((len(qs_train),2))\n",
    "    out_dev=np.zeros((len(qs_dev),2))\n",
    "    history=self.model.fit(x=[qs_train,pos_as_train,neg_as_train], y=[out_train],\n",
    "                           validation_data=([qs_dev,pos_as_dev,neg_as_dev], [out_dev]),\n",
    "                           batch_size=64, \n",
    "                           epochs=15, \n",
    "                           shuffle=True,\n",
    "                           callbacks=[callback])\n",
    "\n",
    "    \n",
    "  def predict(self, examples):\n",
    "    qs, pos_as, neg_as = list(zip(*examples))\n",
    "    qs=np.array(qs)\n",
    "    pos_as=np.array(pos_as)\n",
    "    neg_as=np.array(neg_as)\n",
    "    sims=self.model.predict([qs,pos_as,neg_as])\n",
    "    return sims\n",
    "  \n",
    "  def evaluate(self,qa_groups):\n",
    "    ranks=[]\n",
    "    aps=[]\n",
    "    nExamples=0\n",
    "    for g in qa_groups:\n",
    "      recall_pos=[]\n",
    "      qs, ans, labels = list(zip(*g))\n",
    "      qs=np.array(qs)\n",
    "      ans=np.array(ans)\n",
    "      tmp=np.zeros((qs.shape[0],qs.shape[1]))\n",
    "      sims=self.model.predict([qs,ans,tmp])[:,0]\n",
    "\n",
    "      # sort the simlarities descending\n",
    "      sorted_index=np.argsort(sims)[::-1]\n",
    "\n",
    "      for i in range(len(sorted_index)):\n",
    "        if labels[sorted_index[i]]==1:\n",
    "          # record the postion of correct answers\n",
    "          recall_pos.append(i+1)\n",
    "      recall_pos=np.array(recall_pos)\n",
    "\n",
    "      # calculate the average precision\n",
    "      ap=np.mean((np.arange(len(recall_pos))+1)/recall_pos)\n",
    "      aps.append(ap)\n",
    "\n",
    "      # record the postion of first correct answer\n",
    "      ranks.append(recall_pos[0])\n",
    "\n",
    "    # calculate the mean average precision\n",
    "    MAP=sum(aps)/len(aps)\n",
    "\n",
    "    # calculate the MRR\n",
    "    ranks=np.array(ranks)\n",
    "    MRR=np.mean(1/ranks)\n",
    "    \n",
    "    # calculate accuracy (precision@1)\n",
    "    ACC=sum(ranks==1)/len(ranks)\n",
    "    return MAP, MRR, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-76c2fc4ef8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainExamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevExamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-05db6f52a378>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainExamples, devExamples)\u001b[0m\n\u001b[1;32m     70\u001b[0m                            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                            \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                            callbacks=[callback])\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/dl/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn=nnet()\n",
    "rnn.train(trainExamples, devExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5650921325623169, 0.5706768124740137, 0.42063492063492064)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.evaluate(dev_gs_for_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5478913951680726, 0.5629212286038376, 0.4024896265560166)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.evaluate(test_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru=nnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "812/812 [==============================] - 14s 18ms/step - loss: 0.4262 - val_loss: 0.1149\n",
      "Epoch 2/15\n",
      "812/812 [==============================] - 14s 17ms/step - loss: 0.0649 - val_loss: 0.0660\n",
      "Epoch 3/15\n",
      "812/812 [==============================] - 15s 18ms/step - loss: 0.0357 - val_loss: 0.0506\n",
      "Epoch 4/15\n",
      "812/812 [==============================] - 14s 18ms/step - loss: 0.0280 - val_loss: 0.0478\n",
      "Epoch 5/15\n",
      "812/812 [==============================] - 14s 17ms/step - loss: 0.0251 - val_loss: 0.0464\n",
      "Epoch 6/15\n",
      "812/812 [==============================] - 14s 17ms/step - loss: 0.0233 - val_loss: 0.0435\n",
      "Epoch 7/15\n",
      "812/812 [==============================] - 14s 17ms/step - loss: 0.0221 - val_loss: 0.0416\n",
      "Epoch 8/15\n",
      "812/812 [==============================] - 14s 17ms/step - loss: 0.0215 - val_loss: 0.0397\n",
      "Epoch 9/15\n",
      "812/812 [==============================] - 15s 19ms/step - loss: 0.0211 - val_loss: 0.0434\n",
      "Epoch 10/15\n",
      "812/812 [==============================] - 14s 18ms/step - loss: 0.0204 - val_loss: 0.0430\n",
      "Epoch 11/15\n",
      "812/812 [==============================] - 15s 18ms/step - loss: 0.0200 - val_loss: 0.0438\n"
     ]
    }
   ],
   "source": [
    "gru.train(trainExamples, devExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6217317770172716, 0.63310834434784, 0.4603174603174603)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.evaluate(dev_gs_for_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6169315958735563, 0.6380337694330435, 0.4896265560165975)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.evaluate(test_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
